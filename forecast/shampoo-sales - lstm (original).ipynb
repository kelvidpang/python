{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open( 'score_result.txt', 'w' )\n",
    "f.write('epoch|neuron|rmse \\n' )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=500, neurons=4)  Test RMSE: 162.512916 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1000, neurons=4) Test RMSE: 153.572175 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1500, neurons=4) Test RMSE: 187.092256 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2000, neurons=4) Test RMSE: 141.697755 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2500, neurons=4) Test RMSE: 197.744168 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=3000, neurons=4) Test RMSE: 155.637825 <br>\n",
    "<br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=500, neurons=6) Test RMSE:  153.067551 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1000, neurons=6) Test RMSE: 129.917576 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1500, neurons=6) Test RMSE: 148.941757 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2000, neurons=6) Test RMSE: 155.630252 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2500, neurons=6) Test RMSE:  <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=3000, neurons=6) Test RMSE:  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test RMSE: 111.763\n",
      "2) Test RMSE: 113.596\n",
      "3) Test RMSE: 127.296\n",
      "4) Test RMSE: 119.695\n",
      "5) Test RMSE: 199.791\n",
      "6) Test RMSE: 69.508\n",
      "7) Test RMSE: 112.482\n",
      "8) Test RMSE: 157.857\n",
      "9) Test RMSE: 137.867\n",
      "10) Test RMSE: 112.215\n",
      "11) Test RMSE: 115.586\n",
      "12) Test RMSE: 120.821\n",
      "13) Test RMSE: 73.970\n",
      "14) Test RMSE: 107.743\n",
      "15) Test RMSE: 99.310\n",
      "16) Test RMSE: 96.582\n",
      "17) Test RMSE: 167.223\n",
      "18) Test RMSE: 101.976\n",
      "19) Test RMSE: 99.916\n",
      "20) Test RMSE: 93.648\n",
      "21) Test RMSE: 181.905\n",
      "22) Test RMSE: 112.214\n",
      "23) Test RMSE: 128.272\n",
      "24) Test RMSE: 127.687\n",
      "25) Test RMSE: 86.108\n",
      "26) Test RMSE: 101.088\n",
      "27) Test RMSE: 112.402\n",
      "28) Test RMSE: 73.852\n",
      "29) Test RMSE: 80.044\n",
      "30) Test RMSE: 129.745\n",
      "1) Test RMSE: 113.444\n",
      "2) Test RMSE: 117.740\n",
      "3) Test RMSE: 144.508\n",
      "4) Test RMSE: 83.382\n",
      "5) Test RMSE: 173.715\n",
      "6) Test RMSE: 157.775\n",
      "7) Test RMSE: 132.652\n",
      "8) Test RMSE: 126.696\n",
      "9) Test RMSE: 101.453\n",
      "10) Test RMSE: 220.884\n",
      "11) Test RMSE: 241.329\n",
      "12) Test RMSE: 195.169\n",
      "13) Test RMSE: 75.482\n",
      "14) Test RMSE: 227.518\n",
      "15) Test RMSE: 219.878\n",
      "16) Test RMSE: 192.820\n",
      "17) Test RMSE: 256.960\n",
      "18) Test RMSE: 186.032\n",
      "19) Test RMSE: 166.807\n",
      "20) Test RMSE: 160.205\n",
      "21) Test RMSE: 151.153\n",
      "22) Test RMSE: 150.947\n",
      "23) Test RMSE: 67.972\n",
      "24) Test RMSE: 143.684\n",
      "25) Test RMSE: 117.248\n",
      "26) Test RMSE: 104.305\n",
      "27) Test RMSE: 167.331\n",
      "28) Test RMSE: 100.939\n",
      "29) Test RMSE: 120.681\n",
      "30) Test RMSE: 136.693\n",
      "1) Test RMSE: 196.744\n",
      "2) Test RMSE: 333.565\n",
      "3) Test RMSE: 178.751\n",
      "4) Test RMSE: 81.313\n",
      "5) Test RMSE: 131.010\n",
      "6) Test RMSE: 105.833\n",
      "7) Test RMSE: 121.662\n",
      "8) Test RMSE: 128.773\n",
      "9) Test RMSE: 201.866\n",
      "10) Test RMSE: 149.911\n",
      "11) Test RMSE: 108.493\n",
      "12) Test RMSE: 113.358\n",
      "13) Test RMSE: 56.424\n",
      "14) Test RMSE: 119.971\n",
      "15) Test RMSE: 166.485\n",
      "16) Test RMSE: 89.579\n",
      "17) Test RMSE: 180.060\n",
      "18) Test RMSE: 137.657\n",
      "19) Test RMSE: 83.725\n",
      "20) Test RMSE: 116.455\n",
      "21) Test RMSE: 177.102\n",
      "22) Test RMSE: 103.010\n",
      "23) Test RMSE: 191.309\n",
      "24) Test RMSE: 106.758\n",
      "25) Test RMSE: 196.121\n",
      "26) Test RMSE: 144.813\n",
      "27) Test RMSE: 175.603\n",
      "28) Test RMSE: 168.722\n",
      "29) Test RMSE: 151.774\n",
      "30) Test RMSE: 200.770\n",
      "1) Test RMSE: 168.736\n",
      "2) Test RMSE: 160.018\n",
      "3) Test RMSE: 165.881\n",
      "4) Test RMSE: 162.926\n",
      "5) Test RMSE: 81.349\n",
      "6) Test RMSE: 157.298\n",
      "7) Test RMSE: 85.885\n",
      "8) Test RMSE: 167.305\n",
      "9) Test RMSE: 150.859\n",
      "10) Test RMSE: 165.776\n",
      "11) Test RMSE: 158.227\n",
      "12) Test RMSE: 172.814\n",
      "13) Test RMSE: 156.546\n",
      "14) Test RMSE: 89.445\n",
      "15) Test RMSE: 180.755\n",
      "16) Test RMSE: 131.040\n",
      "17) Test RMSE: 213.529\n",
      "18) Test RMSE: 195.961\n",
      "19) Test RMSE: 144.864\n",
      "20) Test RMSE: 105.220\n",
      "21) Test RMSE: 182.621\n",
      "22) Test RMSE: 183.335\n",
      "23) Test RMSE: 137.657\n",
      "24) Test RMSE: 291.743\n",
      "25) Test RMSE: 91.833\n",
      "26) Test RMSE: 93.650\n",
      "27) Test RMSE: 155.951\n",
      "28) Test RMSE: 152.521\n",
      "29) Test RMSE: 88.146\n",
      "30) Test RMSE: 103.319\n",
      "1) Test RMSE: 114.276\n",
      "2) Test RMSE: 163.526\n",
      "3) Test RMSE: 176.853\n",
      "4) Test RMSE: 81.667\n",
      "5) Test RMSE: 118.026\n",
      "6) Test RMSE: 216.158\n",
      "7) Test RMSE: 143.015\n",
      "8) Test RMSE: 116.959\n",
      "9) Test RMSE: 162.873\n",
      "10) Test RMSE: 83.664\n",
      "11) Test RMSE: 87.338\n",
      "12) Test RMSE: 114.878\n",
      "13) Test RMSE: 203.782\n",
      "14) Test RMSE: 157.486\n",
      "15) Test RMSE: 121.676\n",
      "16) Test RMSE: 122.707\n",
      "17) Test RMSE: 95.848\n",
      "18) Test RMSE: 123.812\n",
      "19) Test RMSE: 102.299\n",
      "20) Test RMSE: 162.746\n",
      "21) Test RMSE: 93.772\n",
      "22) Test RMSE: 67.012\n",
      "23) Test RMSE: 162.572\n",
      "24) Test RMSE: 140.964\n",
      "25) Test RMSE: 207.735\n",
      "26) Test RMSE: 78.080\n",
      "27) Test RMSE: 185.206\n",
      "28) Test RMSE: 179.705\n",
      "29) Test RMSE: 114.112\n",
      "30) Test RMSE: 58.334\n",
      "1) Test RMSE: 177.570\n",
      "2) Test RMSE: 153.239\n",
      "3) Test RMSE: 107.238\n",
      "4) Test RMSE: 223.930\n",
      "5) Test RMSE: 163.779\n",
      "6) Test RMSE: 118.585\n",
      "7) Test RMSE: 157.519\n",
      "8) Test RMSE: 185.447\n",
      "9) Test RMSE: 222.483\n",
      "10) Test RMSE: 89.103\n",
      "11) Test RMSE: 210.438\n",
      "12) Test RMSE: 109.527\n",
      "13) Test RMSE: 220.294\n",
      "14) Test RMSE: 158.978\n",
      "15) Test RMSE: 142.029\n",
      "16) Test RMSE: 163.252\n",
      "17) Test RMSE: 175.652\n",
      "18) Test RMSE: 103.199\n",
      "19) Test RMSE: 154.831\n",
      "20) Test RMSE: 125.985\n",
      "21) Test RMSE: 91.304\n",
      "22) Test RMSE: 92.012\n",
      "23) Test RMSE: 196.047\n",
      "24) Test RMSE: 218.094\n",
      "25) Test RMSE: 109.289\n",
      "26) Test RMSE: 144.267\n",
      "27) Test RMSE: 160.393\n",
      "28) Test RMSE: 184.914\n",
      "29) Test RMSE: 101.374\n",
      "30) Test RMSE: 160.172\n",
      "1) Test RMSE: 201.728\n",
      "2) Test RMSE: 158.338\n",
      "3) Test RMSE: 202.568\n",
      "4) Test RMSE: 89.203\n",
      "5) Test RMSE: 222.261\n",
      "6) Test RMSE: 158.152\n",
      "7) Test RMSE: 170.980\n",
      "8) Test RMSE: 104.292\n",
      "9) Test RMSE: 99.691\n",
      "10) Test RMSE: 171.505\n",
      "11) Test RMSE: 117.184\n",
      "12) Test RMSE: 138.089\n",
      "13) Test RMSE: 217.895\n",
      "14) Test RMSE: 163.751\n",
      "15) Test RMSE: 91.174\n",
      "16) Test RMSE: 89.446\n",
      "17) Test RMSE: 100.193\n",
      "18) Test RMSE: 155.621\n",
      "19) Test RMSE: 168.901\n",
      "20) Test RMSE: 197.962\n",
      "21) Test RMSE: 76.626\n",
      "22) Test RMSE: 156.568\n",
      "23) Test RMSE: 135.763\n",
      "24) Test RMSE: 66.882\n",
      "25) Test RMSE: 176.462\n",
      "26) Test RMSE: 189.811\n",
      "27) Test RMSE: 147.760\n",
      "28) Test RMSE: 93.519\n",
      "29) Test RMSE: 170.175\n",
      "30) Test RMSE: 227.131\n",
      "1) Test RMSE: 152.925\n",
      "2) Test RMSE: 169.755\n",
      "3) Test RMSE: 127.265\n",
      "4) Test RMSE: 164.945\n",
      "5) Test RMSE: 143.037\n",
      "6) Test RMSE: 122.651\n",
      "7) Test RMSE: 126.187\n",
      "8) Test RMSE: 114.601\n",
      "9) Test RMSE: 147.068\n",
      "10) Test RMSE: 155.019\n",
      "11) Test RMSE: 107.607\n",
      "12) Test RMSE: 203.028\n",
      "13) Test RMSE: 102.121\n",
      "14) Test RMSE: 80.987\n",
      "15) Test RMSE: 136.665\n",
      "16) Test RMSE: 100.063\n",
      "17) Test RMSE: 81.315\n",
      "18) Test RMSE: 104.521\n",
      "19) Test RMSE: 182.134\n",
      "20) Test RMSE: 118.014\n",
      "21) Test RMSE: 157.334\n",
      "22) Test RMSE: 182.147\n",
      "23) Test RMSE: 96.701\n",
      "24) Test RMSE: 191.796\n",
      "25) Test RMSE: 150.512\n",
      "26) Test RMSE: 104.116\n",
      "27) Test RMSE: 140.587\n",
      "28) Test RMSE: 105.828\n",
      "29) Test RMSE: 120.924\n",
      "30) Test RMSE: 177.598\n",
      "1) Test RMSE: 86.102\n",
      "2) Test RMSE: 230.136\n",
      "3) Test RMSE: 198.423\n",
      "4) Test RMSE: 217.009\n",
      "5) Test RMSE: 96.854\n",
      "6) Test RMSE: 116.175\n",
      "7) Test RMSE: 97.739\n",
      "8) Test RMSE: 114.822\n",
      "9) Test RMSE: 100.603\n",
      "10) Test RMSE: 79.986\n",
      "11) Test RMSE: 103.141\n",
      "12) Test RMSE: 210.302\n",
      "13) Test RMSE: 163.539\n",
      "14) Test RMSE: 129.023\n",
      "15) Test RMSE: 104.171\n",
      "16) Test RMSE: 163.006\n",
      "17) Test RMSE: 139.656\n",
      "18) Test RMSE: 101.076\n",
      "19) Test RMSE: 154.766\n",
      "20) Test RMSE: 201.071\n",
      "21) Test RMSE: 101.210\n",
      "22) Test RMSE: 152.220\n",
      "23) Test RMSE: 76.818\n",
      "24) Test RMSE: 203.223\n",
      "25) Test RMSE: 120.806\n",
      "26) Test RMSE: 181.598\n",
      "27) Test RMSE: 146.767\n",
      "28) Test RMSE: 193.768\n",
      "29) Test RMSE: 76.481\n",
      "30) Test RMSE: 204.583\n",
      "1) Test RMSE: 160.699\n",
      "2) Test RMSE: 136.414\n",
      "3) Test RMSE: 126.391\n",
      "4) Test RMSE: 76.562\n",
      "5) Test RMSE: 132.850\n",
      "6) Test RMSE: 153.637\n",
      "7) Test RMSE: 129.986\n",
      "8) Test RMSE: 148.966\n",
      "9) Test RMSE: 193.239\n",
      "10) Test RMSE: 259.159\n",
      "11) Test RMSE: 86.200\n",
      "12) Test RMSE: 260.302\n",
      "13) Test RMSE: 108.922\n",
      "14) Test RMSE: 71.304\n",
      "15) Test RMSE: 115.069\n",
      "16) Test RMSE: 87.790\n",
      "17) Test RMSE: 205.506\n",
      "18) Test RMSE: 227.560\n",
      "19) Test RMSE: 166.573\n",
      "20) Test RMSE: 120.261\n",
      "21) Test RMSE: 317.530\n",
      "22) Test RMSE: 199.899\n",
      "23) Test RMSE: 100.851\n",
      "24) Test RMSE: 99.423\n",
      "25) Test RMSE: 109.274\n",
      "26) Test RMSE: 295.948\n",
      "27) Test RMSE: 87.274\n",
      "28) Test RMSE: 107.663\n",
      "29) Test RMSE: 156.543\n",
      "30) Test RMSE: 92.953\n",
      "1) Test RMSE: 110.303\n",
      "2) Test RMSE: 116.259\n",
      "3) Test RMSE: 199.421\n",
      "4) Test RMSE: 171.756\n",
      "5) Test RMSE: 100.978\n",
      "6) Test RMSE: 162.742\n",
      "7) Test RMSE: 106.985\n",
      "8) Test RMSE: 150.550\n",
      "9) Test RMSE: 101.126\n",
      "10) Test RMSE: 99.479\n",
      "11) Test RMSE: 104.641\n",
      "12) Test RMSE: 87.154\n",
      "13) Test RMSE: 109.826\n",
      "14) Test RMSE: 94.914\n",
      "15) Test RMSE: 100.082\n",
      "16) Test RMSE: 196.988\n",
      "17) Test RMSE: 130.816\n",
      "18) Test RMSE: 162.245\n",
      "19) Test RMSE: 205.250\n",
      "20) Test RMSE: 106.368\n",
      "21) Test RMSE: 113.625\n",
      "22) Test RMSE: 107.750\n",
      "23) Test RMSE: 149.182\n",
      "24) Test RMSE: 122.624\n",
      "25) Test RMSE: 121.484\n",
      "26) Test RMSE: 144.344\n",
      "27) Test RMSE: 127.932\n",
      "28) Test RMSE: 85.569\n",
      "29) Test RMSE: 138.713\n",
      "30) Test RMSE: 186.272\n",
      "1) Test RMSE: 158.870\n",
      "2) Test RMSE: 181.172\n",
      "3) Test RMSE: 142.987\n",
      "4) Test RMSE: 97.687\n",
      "5) Test RMSE: 95.536\n",
      "6) Test RMSE: 103.143\n",
      "7) Test RMSE: 186.227\n",
      "8) Test RMSE: 112.645\n",
      "9) Test RMSE: 247.125\n",
      "10) Test RMSE: 142.468\n",
      "11) Test RMSE: 200.619\n",
      "12) Test RMSE: 86.910\n",
      "13) Test RMSE: 129.422\n",
      "14) Test RMSE: 97.737\n",
      "15) Test RMSE: 115.470\n",
      "16) Test RMSE: 107.848\n",
      "17) Test RMSE: 97.201\n",
      "18) Test RMSE: 125.700\n",
      "19) Test RMSE: 185.079\n",
      "20) Test RMSE: 167.618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-14961f3907c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlstm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;31m# forecast the entire training dataset to build up state for forecasting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtrain_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5b13e9c77d75>\u001b[0m in \u001b[0;36mfit_lstm\u001b[1;34m(train, batch_size, nb_epoch, neurons)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kckpang\\appdata\\local\\conda\\conda\\envs\\python3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\users\\kckpang\\appdata\\local\\conda\\conda\\envs\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kckpang\\appdata\\local\\conda\\conda\\envs\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kckpang\\appdata\\local\\conda\\conda\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2263\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2264\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2265\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kckpang\\appdata\\local\\conda\\conda\\envs\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "nb_epoch_range=[500,1000,1500,2000,2500,3000]\n",
    "neuron_range=[2,4,6,8,10]\n",
    "for i1 in nb_epoch_range:\n",
    "    for i2 in neuron_range:\n",
    "        # repeat experiment\n",
    "        repeats = 30\n",
    "        error_scores = []\n",
    "        for r in range(repeats):\n",
    "            # fit the model\n",
    "            lstm_model = fit_lstm(train_scaled, 1, i1, i2)\n",
    "            # forecast the entire training dataset to build up state for forecasting\n",
    "            train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "            lstm_model.predict(train_reshaped, batch_size=1)\n",
    "            # walk-forward validation on the test data\n",
    "            predictions = list()\n",
    "            for i in range(len(test_scaled)):\n",
    "                # make one-step forecast\n",
    "                X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "                yhat = forecast_lstm(lstm_model, 1, X)\n",
    "                # invert scaling\n",
    "                yhat = invert_scale(scaler, X, yhat)\n",
    "                # invert differencing\n",
    "                yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "                # store forecast\n",
    "                predictions.append(yhat)\n",
    "            # report performance\n",
    "            rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "            print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "            #error_scores.append([rmse])\n",
    " \n",
    "            f = open( 'score_result.txt', 'a' )\n",
    "            f.write(str(i1)+'|'+str(i2)+'|'+str(rmse)+'\\n' )\n",
    "            f.close()\n",
    "\n",
    "print(\"done\")\n",
    "# summarize results\n",
    "#results = DataFrame()\n",
    "#results['rmse'] = error_scores\n",
    "#mean=results.mean()\n",
    "#print(results.describe())\n",
    "#results.boxplot()\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
