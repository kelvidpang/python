{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open( 'score_result.txt', 'w' )\n",
    "f.write('epoch|neuron|rmse \\n' )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=500, neurons=4)  Test RMSE: 162.512916 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1000, neurons=4) Test RMSE: 153.572175 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1500, neurons=4) Test RMSE: 187.092256 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2000, neurons=4) Test RMSE: 141.697755 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2500, neurons=4) Test RMSE: 197.744168 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=3000, neurons=4) Test RMSE: 155.637825 <br>\n",
    "<br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=500, neurons=6) Test RMSE:  153.067551 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1000, neurons=6) Test RMSE: 129.917576 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=1500, neurons=6) Test RMSE: 148.941757 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2000, neurons=6) Test RMSE: 155.630252 <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=2500, neurons=6) Test RMSE:  <br>\n",
    "fit_lstm(train_scaled, batch_size=1, nb_epoch=3000, neurons=6) Test RMSE:  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test RMSE: 127.635\n",
      "2) Test RMSE: 116.612\n",
      "3) Test RMSE: 120.924\n",
      "4) Test RMSE: 103.931\n",
      "5) Test RMSE: 124.671\n",
      "6) Test RMSE: 126.841\n",
      "7) Test RMSE: 112.527\n",
      "8) Test RMSE: 100.709\n",
      "9) Test RMSE: 111.842\n",
      "10) Test RMSE: 125.830\n",
      "1) Test RMSE: 112.781\n",
      "2) Test RMSE: 99.432\n",
      "3) Test RMSE: 113.375\n",
      "4) Test RMSE: 101.409\n",
      "5) Test RMSE: 88.037\n",
      "6) Test RMSE: 106.655\n",
      "7) Test RMSE: 99.561\n",
      "8) Test RMSE: 99.273\n",
      "9) Test RMSE: 104.968\n",
      "10) Test RMSE: 119.513\n",
      "1) Test RMSE: 102.347\n",
      "2) Test RMSE: 95.456\n",
      "3) Test RMSE: 80.892\n",
      "4) Test RMSE: 75.286\n",
      "5) Test RMSE: 95.043\n",
      "6) Test RMSE: 89.634\n",
      "7) Test RMSE: 104.546\n",
      "8) Test RMSE: 90.148\n",
      "9) Test RMSE: 90.809\n",
      "10) Test RMSE: 98.415\n",
      "1) Test RMSE: 105.054\n",
      "2) Test RMSE: 88.437\n",
      "3) Test RMSE: 77.894\n",
      "4) Test RMSE: 102.731\n",
      "5) Test RMSE: 98.663\n",
      "6) Test RMSE: 97.814\n",
      "7) Test RMSE: 107.410\n",
      "8) Test RMSE: 76.226\n",
      "9) Test RMSE: 96.303\n",
      "10) Test RMSE: 114.449\n",
      "1) Test RMSE: 97.548\n",
      "2) Test RMSE: 96.610\n",
      "3) Test RMSE: 105.193\n",
      "4) Test RMSE: 93.028\n",
      "5) Test RMSE: 84.379\n",
      "6) Test RMSE: 112.341\n",
      "7) Test RMSE: 97.871\n",
      "8) Test RMSE: 84.147\n",
      "9) Test RMSE: 67.033\n",
      "10) Test RMSE: 102.956\n",
      "1) Test RMSE: 92.279\n",
      "2) Test RMSE: 92.462\n",
      "3) Test RMSE: 104.629\n",
      "4) Test RMSE: 106.048\n",
      "5) Test RMSE: 93.719\n",
      "6) Test RMSE: 105.705\n",
      "7) Test RMSE: 100.891\n",
      "8) Test RMSE: 99.535\n",
      "9) Test RMSE: 103.481\n",
      "10) Test RMSE: 100.658\n",
      "1) Test RMSE: 66.960\n",
      "2) Test RMSE: 95.713\n",
      "3) Test RMSE: 95.880\n",
      "4) Test RMSE: 97.228\n",
      "5) Test RMSE: 107.947\n",
      "6) Test RMSE: 114.263\n",
      "7) Test RMSE: 66.546\n",
      "8) Test RMSE: 109.912\n",
      "9) Test RMSE: 79.384\n",
      "10) Test RMSE: 106.388\n",
      "1) Test RMSE: 108.652\n",
      "2) Test RMSE: 96.049\n",
      "3) Test RMSE: 136.897\n",
      "4) Test RMSE: 105.167\n",
      "5) Test RMSE: 107.907\n",
      "6) Test RMSE: 66.597\n",
      "7) Test RMSE: 108.399\n",
      "8) Test RMSE: 80.214\n",
      "9) Test RMSE: 99.212\n",
      "10) Test RMSE: 102.743\n",
      "1) Test RMSE: 131.193\n",
      "2) Test RMSE: 102.747\n",
      "3) Test RMSE: 134.480\n",
      "4) Test RMSE: 98.891\n",
      "5) Test RMSE: 106.189\n",
      "6) Test RMSE: 91.331\n",
      "7) Test RMSE: 108.311\n",
      "8) Test RMSE: 100.181\n",
      "9) Test RMSE: 76.756\n",
      "10) Test RMSE: 101.548\n",
      "1) Test RMSE: 71.116\n",
      "2) Test RMSE: 146.493\n",
      "3) Test RMSE: 110.795\n",
      "4) Test RMSE: 72.438\n",
      "5) Test RMSE: 103.488\n",
      "6) Test RMSE: 103.837\n",
      "7) Test RMSE: 102.950\n",
      "8) Test RMSE: 100.338\n",
      "9) Test RMSE: 156.551\n",
      "10) Test RMSE: 71.181\n",
      "1) Test RMSE: 110.060\n",
      "2) Test RMSE: 131.005\n",
      "3) Test RMSE: 105.970\n",
      "4) Test RMSE: 108.935\n",
      "5) Test RMSE: 126.265\n",
      "6) Test RMSE: 104.940\n",
      "7) Test RMSE: 114.557\n",
      "8) Test RMSE: 112.554\n",
      "9) Test RMSE: 114.531\n",
      "10) Test RMSE: 119.902\n",
      "1) Test RMSE: 110.344\n",
      "2) Test RMSE: 78.506\n",
      "3) Test RMSE: 118.871\n",
      "4) Test RMSE: 129.430\n",
      "5) Test RMSE: 103.204\n",
      "6) Test RMSE: 115.587\n",
      "7) Test RMSE: 97.655\n",
      "8) Test RMSE: 139.318\n",
      "9) Test RMSE: 114.221\n",
      "10) Test RMSE: 120.417\n",
      "1) Test RMSE: 84.020\n",
      "2) Test RMSE: 91.146\n",
      "3) Test RMSE: 112.844\n",
      "4) Test RMSE: 143.266\n",
      "5) Test RMSE: 98.923\n",
      "6) Test RMSE: 175.979\n",
      "7) Test RMSE: 118.208\n",
      "8) Test RMSE: 114.990\n",
      "9) Test RMSE: 98.604\n",
      "10) Test RMSE: 85.781\n",
      "1) Test RMSE: 161.713\n",
      "2) Test RMSE: 103.012\n",
      "3) Test RMSE: 91.264\n",
      "4) Test RMSE: 97.115\n",
      "5) Test RMSE: 101.586\n",
      "6) Test RMSE: 69.283\n",
      "7) Test RMSE: 59.675\n",
      "8) Test RMSE: 86.948\n",
      "9) Test RMSE: 148.014\n",
      "10) Test RMSE: 99.818\n",
      "1) Test RMSE: 106.139\n",
      "2) Test RMSE: 82.611\n",
      "3) Test RMSE: 115.442\n",
      "4) Test RMSE: 123.032\n",
      "5) Test RMSE: 161.729\n",
      "6) Test RMSE: 119.721\n",
      "7) Test RMSE: 141.268\n",
      "8) Test RMSE: 144.558\n",
      "9) Test RMSE: 186.539\n",
      "10) Test RMSE: 128.164\n",
      "1) Test RMSE: 178.727\n",
      "2) Test RMSE: 201.183\n",
      "3) Test RMSE: 83.193\n",
      "4) Test RMSE: 167.455\n",
      "5) Test RMSE: 144.004\n",
      "6) Test RMSE: 152.835\n",
      "7) Test RMSE: 141.803\n",
      "8) Test RMSE: 185.264\n",
      "9) Test RMSE: 169.492\n",
      "10) Test RMSE: 92.531\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-914166c6a3d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# forecast the entire training dataset to build up state for forecasting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5b13e9c77d75>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(train, batch_size, nb_epoch, neurons)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvidpang/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "nb_epoch_range=range(100,1100,100)\n",
    "neuron_range=range(1,11)\n",
    "for i1 in nb_epoch_range:\n",
    "    for i2 in neuron_range:\n",
    "        # repeat experiment\n",
    "        repeats = 10\n",
    "        error_scores = []\n",
    "        for r in range(repeats):\n",
    "            # fit the model\n",
    "            lstm_model = fit_lstm(train_scaled, 1, i1, i2)\n",
    "            # forecast the entire training dataset to build up state for forecasting\n",
    "            train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "            lstm_model.predict(train_reshaped, batch_size=1)\n",
    "            # walk-forward validation on the test data\n",
    "            predictions = list()\n",
    "            for i in range(len(test_scaled)):\n",
    "                # make one-step forecast\n",
    "                X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "                yhat = forecast_lstm(lstm_model, 1, X)\n",
    "                # invert scaling\n",
    "                yhat = invert_scale(scaler, X, yhat)\n",
    "                # invert differencing\n",
    "                yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "                # store forecast\n",
    "                predictions.append(yhat)\n",
    "            # report performance\n",
    "            rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "            #print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "            #error_scores.append([rmse])\n",
    " \n",
    "            f = open( 'score_result.txt', 'a' )\n",
    "            f.write(str(i1)+'|'+str(i2)+'|'+str(rmse)+'\\n' )\n",
    "            f.close()\n",
    "\n",
    "print(\"done\")\n",
    "# summarize results\n",
    "#results = DataFrame()\n",
    "#results['rmse'] = error_scores\n",
    "#mean=results.mean()\n",
    "#print(results.describe())\n",
    "#results.boxplot()\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('score_result.txt',  sep='|')\n",
    "df.pivot_table(index='epoch',columns='neuron',aggfunc=('count','mean'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
